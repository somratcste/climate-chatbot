{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Nazmul\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Nazmul\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Nazmul Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Nazmul\n",
      "[nltk_data]     Hossain\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings\n",
    "import os, json\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from nltk.stem import wordnet # to perform lemmatization\n",
    "from sklearn.feature_extraction.text import CountVectorizer # to perform bow\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # to perform tfidf\n",
    "from nltk import pos_tag # for parts of speech \n",
    "from sklearn.metrics import pairwise_distances # tor perform cosine similarity \n",
    "from nltk import word_tokenize # to create tokens\n",
    "from nltk.corpus import stopwords # for stop words \n",
    "nltk.download('punkt') \n",
    "nltk.download('wordnet') \n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyText(text):\n",
    "     return unidecode(text.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get question and nested answer \n",
    "data = []\n",
    "with open('data/climatology-1.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "def traverseAnswerObjects(answersObjects):\n",
    "    print(\"answer: \" + answersObjects[\"text\"])\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    if(len(answersObjects[\"answers\"])):\n",
    "        for answerObject in answersObjects[\"answers\"]:\n",
    "            traverseAnswerObjects(answerObject)\n",
    "\n",
    "for questionObject in data:\n",
    "    print(\"Question: \"+ questionObject[\"question\"])\n",
    "    print(\"\\n\")\n",
    "    traverseAnswerObjects(questionObject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get question and first answer \n",
    "# Get all json file from a directory\n",
    "path_to_json = 'data/'\n",
    "columns = ['question', 'answer']\n",
    "questionAndAnswerDf = pd.DataFrame(columns=columns)\n",
    "indexCount = 0\n",
    "for pos_json in os.listdir(path_to_json):\n",
    "    if pos_json.endswith('.json'):\n",
    "        with open(path_to_json + pos_json, encoding=\"utf8\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for index, questionObject in enumerate(data):\n",
    "                answer = []\n",
    "                if(len(questionObject[\"answers\"])):\n",
    "                    answer = questionObject[\"answers\"][0][\"text\"]\n",
    "                else :\n",
    "                    answer = questionObject[\"text\"]\n",
    "                questionAndAnswerDf.loc[indexCount] = [getBeautifyText(questionObject[\"question\"]), getBeautifyText(answer)]\n",
    "                indexCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How do you compare Methane Ppm and carbon(iv) ...</td>\n",
       "      <td>Closed. This question needs details or clarity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Equatorial Bulge and its implications on the c...</td>\n",
       "      <td>How much of the variance in the climate is due...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Where oil is used for [closed]</td>\n",
       "      <td>OilPrice Petrochemicals are used to make numer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rain Water vs Sprinkler Irrigation</td>\n",
       "      <td>I think what you mean by thermo-electric nitro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Climate Change in the North</td>\n",
       "      <td>Why has it been so warm in Moscow, Russia the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How do you compare Methane Ppm and carbon(iv) ...   \n",
       "1  Equatorial Bulge and its implications on the c...   \n",
       "2                     Where oil is used for [closed]   \n",
       "3                 Rain Water vs Sprinkler Irrigation   \n",
       "4                        Climate Change in the North   \n",
       "\n",
       "                                              answer  \n",
       "0  Closed. This question needs details or clarity...  \n",
       "1  How much of the variance in the climate is due...  \n",
       "2  OilPrice Petrochemicals are used to make numer...  \n",
       "3  I think what you mean by thermo-electric nitro...  \n",
       "4  Why has it been so warm in Moscow, Russia the ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fills the null value with previous value\n",
    "questionAndAnswerDf.ffill(axis = 0, inplace = True)\n",
    "questionAndAnswerDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3233"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionAndAnswerDf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go to play football'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function that performs text normalization steps \n",
    "def text_normalization(text):\n",
    "    text = str(text).lower() # text to lower case\n",
    "    spl_char_text = re.sub(r'[^a-z0-9]', ' ', text) # removing special characters\n",
    "    tokens = nltk.word_tokenize(spl_char_text) # word tokenizing\n",
    "    lema = wordnet.WordNetLemmatizer() # initializing lemmatization\n",
    "    tags_list = pos_tag(tokens, tagset = None) # parts of speech\n",
    "    lema_words = [] # empty list\n",
    "    for token,pos_token in tags_list:\n",
    "        if pos_token.startswith('V'): # verb\n",
    "            pos_val = 'v'\n",
    "        elif pos_token.startswith('J'): # adjective\n",
    "            pos_val = 'a'\n",
    "        elif pos_token.startswith('R'): # adverb\n",
    "            pos_val = 'r'\n",
    "        else: \n",
    "            pos_val = 'n' # noun\n",
    "        lema_token = lema.lemmatize(token, pos_val) # performing lemmatization\n",
    "        lema_words.append(lema_token) # appending the lemmatized token into a list \n",
    "    return \" \".join(lema_words) # returns the lemmatized tokens as a sentence\n",
    "text_normalization(\"going to play football\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How do you compare Methane Ppm and carbon(iv) ...</td>\n",
       "      <td>Closed. This question needs details or clarity...</td>\n",
       "      <td>how do you compare methane ppm and carbon iv o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Equatorial Bulge and its implications on the c...</td>\n",
       "      <td>How much of the variance in the climate is due...</td>\n",
       "      <td>equatorial bulge and it implication on the cli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Where oil is used for [closed]</td>\n",
       "      <td>OilPrice Petrochemicals are used to make numer...</td>\n",
       "      <td>where oil be use for closed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rain Water vs Sprinkler Irrigation</td>\n",
       "      <td>I think what you mean by thermo-electric nitro...</td>\n",
       "      <td>rain water v sprinkler irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Climate Change in the North</td>\n",
       "      <td>Why has it been so warm in Moscow, Russia the ...</td>\n",
       "      <td>climate change in the north</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  How do you compare Methane Ppm and carbon(iv) ...   \n",
       "1  Equatorial Bulge and its implications on the c...   \n",
       "2                     Where oil is used for [closed]   \n",
       "3                 Rain Water vs Sprinkler Irrigation   \n",
       "4                        Climate Change in the North   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Closed. This question needs details or clarity...   \n",
       "1  How much of the variance in the climate is due...   \n",
       "2  OilPrice Petrochemicals are used to make numer...   \n",
       "3  I think what you mean by thermo-electric nitro...   \n",
       "4  Why has it been so warm in Moscow, Russia the ...   \n",
       "\n",
       "                                     lemmatized_text  \n",
       "0  how do you compare methane ppm and carbon iv o...  \n",
       "1  equatorial bulge and it implication on the cli...  \n",
       "2                        where oil be use for closed  \n",
       "3                  rain water v sprinkler irrigation  \n",
       "4                        climate change in the north  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function to the dataset to get clean text\n",
    "questionAndAnswerDf[\"lemmatized_text\"] = questionAndAnswerDf[\"question\"].apply(text_normalization) \n",
    "questionAndAnswerDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>0d</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>101</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelenskyy</th>\n",
       "      <th>zeller</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipcar</th>\n",
       "      <th>zone</th>\n",
       "      <th>zugluft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 4022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000  03  04  0d  10  100  1000  10000  101  105  ...  your  youth  youtube  \\\n",
       "0    0   0   0   0   0    0     0      0    0    0  ...     0      0        0   \n",
       "1    0   0   0   0   0    0     0      0    0    0  ...     0      0        0   \n",
       "2    0   0   0   0   0    0     0      0    0    0  ...     0      0        0   \n",
       "3    0   0   0   0   0    0     0      0    0    0  ...     0      0        0   \n",
       "4    0   0   0   0   0    0     0      0    0    0  ...     0      0        0   \n",
       "\n",
       "   zealand  zelenskyy  zeller  zero  zipcar  zone  zugluft  \n",
       "0        0          0       0     0       0     0        0  \n",
       "1        0          0       0     0       0     0        0  \n",
       "2        0          0       0     0       0     0        0  \n",
       "3        0          0       0     0       0     0        0  \n",
       "4        0          0       0     0       0     0        0  \n",
       "\n",
       "[5 rows x 4022 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bow of words\n",
    "cv = CountVectorizer() # initializing the count vectorizer\n",
    "X = cv.fit_transform(questionAndAnswerDf[\"lemmatized_text\"]).toarray()\n",
    "\n",
    "# returns all the unique word from data\n",
    "features = cv.get_feature_names()\n",
    "questionAndAnswerDf_bou = pd.DataFrame(X, columns = features)\n",
    "questionAndAnswerDf_bou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>0d</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10000</th>\n",
       "      <th>101</th>\n",
       "      <th>105</th>\n",
       "      <th>...</th>\n",
       "      <th>your</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zelenskyy</th>\n",
       "      <th>zeller</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipcar</th>\n",
       "      <th>zone</th>\n",
       "      <th>zugluft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 4022 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   000   03   04   0d   10  100  1000  10000  101  105  ...  your  youth  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0    0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0    0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0    0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0    0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0   0.0    0.0  0.0  0.0  ...   0.0    0.0   \n",
       "\n",
       "   youtube  zealand  zelenskyy  zeller  zero  zipcar  zone  zugluft  \n",
       "0      0.0      0.0        0.0     0.0   0.0     0.0   0.0      0.0  \n",
       "1      0.0      0.0        0.0     0.0   0.0     0.0   0.0      0.0  \n",
       "2      0.0      0.0        0.0     0.0   0.0     0.0   0.0      0.0  \n",
       "3      0.0      0.0        0.0     0.0   0.0     0.0   0.0      0.0  \n",
       "4      0.0      0.0        0.0     0.0   0.0     0.0   0.0      0.0  \n",
       "\n",
       "[5 rows x 4022 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using tf-idf\n",
    "tfidf = TfidfVectorizer() # intializing tf-id\n",
    "x_tfidf = tfidf.fit_transform(questionAndAnswerDf[\"lemmatized_text\"]).toarray() # transforming the data into array\n",
    "\n",
    "# returns all the unique word from data with a scroe of that word \n",
    "questionAndAnswerDf_tfidf = pd.DataFrame(x_tfidf, columns = tfidf.get_feature_names())\n",
    "questionAndAnswerDf_tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "greets = (\"hi\", \"hello\", \"good evening\", \"good afternoon\", \"hi there\",\n",
    "          \"good morning\", \"morning\", \"evening\", \"hey\", \"hey there\")\n",
    "\n",
    "identity_qs = (\"what are you\", \"who are you\")\n",
    "\n",
    "thanks = (\"thanks\", \"thank you\", \"thank you very much\", \"thank you so much\")\n",
    "\n",
    "farewells = (\"bye\", \"goodbye\", \"see ya\", \"see you\", \"cheers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that returns response to query\n",
    "def generate_response(text):\n",
    "    lemma = text_normalization(text) # text normalization\n",
    "    tf = tfidf.transform([lemma]).toarray() # apply tf-idf\n",
    "    cos = 1 - pairwise_distances(questionAndAnswerDf_tfidf, tf, metric = \"cosine\") # apply cosine similarity\n",
    "    index_value = cos.argmax() # getting index value\n",
    "    return questionAndAnswerDf[\"answer\"].loc[index_value][:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi I'm Newbie.Have a good day\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(\"hi asdf adsf asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function for server\n",
    "def final_response(text):\n",
    "#     human_txt = text.decode('utf-8')\n",
    "    human_txt = text\n",
    "    if human_txt not in farewells and human_txt not in thanks:\n",
    "        if human_txt in greets:\n",
    "            return \"Captain Planet: \" + random.choice(greets)\n",
    "        elif human_txt in identity_qs:\n",
    "            return \"Captain Planet: I am a chatbot developed in a data science project at the University of Bremen. I am here to answer your questions about climate change.\"\n",
    "        else:\n",
    "            return \"Captain Planet: \" + generate_response(human_txt)\n",
    "    else:\n",
    "        if human_txt in thanks:\n",
    "            return \"Captain Planet: You're welcome!\"\n",
    "        else:\n",
    "            return \"Captain Planet: Goodbye and thanks for your interest in climate change!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat bot\n",
    "keep_dialogue_alive = True\n",
    "print(\"Hello, I am Captain Planet. Please ask me any question regarding climate change. üí™üåç\")\n",
    "while(keep_dialogue_alive):\n",
    "    human_txt = input().lower()\n",
    "    if human_txt not in farewells and human_txt not in thanks:\n",
    "        if human_txt in greets:\n",
    "            print(\"Captain Planet: \" + random.choice(greets))\n",
    "        elif human_txt in identity_qs:\n",
    "            print(\"Captain Planet: \"\n",
    "                  + \"I am a chatbot developed in a data science project \"\n",
    "                  + \"at the University of Bremen. I am here to answer your questions about climate change.\")\n",
    "        else:\n",
    "            print(\"Captain Planet: \" + generate_response(human_txt))\n",
    "    else:\n",
    "        keep_dialogue_alive = False\n",
    "        if human_txt in thanks:\n",
    "            print(\"Captain Planet: You're welcome!\")\n",
    "        else:\n",
    "            print(\"Captain Planet: Goodbye and thanks for your interest in climate change!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResponse = final_response(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model using pickle\n",
    "import pickle\n",
    "filename = 'retrieval_model.pkl'\n",
    "pickle.dump(final_response, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Captain Planet: hey'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('retrieval_model.pkl', 'rb'))\n",
    "loaded_model(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the server block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.server\n",
    "import socketserver\n",
    "\n",
    "PORT = 8080\n",
    "DIRECTORY = 'public'\n",
    "\n",
    "class Handler(http.server.SimpleHTTPRequestHandler):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, directory=DIRECTORY, **kwargs)\n",
    "\n",
    "    def do_POST(self):\n",
    "        self.send_response(200)\n",
    "        content_length = int(self.headers['Content-Length'])\n",
    "        post_body = self.rfile.read(content_length)\n",
    "        self.end_headers()\n",
    "        chatbot_reply = final_response(post_body)\n",
    "        self.wfile.write(str.encode(chatbot_reply))\n",
    "\n",
    "with socketserver.TCPServer(('', PORT), Handler) as httpd:\n",
    "    print('serving at port', PORT)\n",
    "    try:\n",
    "        httpd.serve_forever()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    httpd.server_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
