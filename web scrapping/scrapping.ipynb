{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from time import sleep \n",
    "from random import randint\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyDate(dateTimeString):\n",
    "    return dateTimeString.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyText(text):\n",
    "    return text.replace('\\n', '').replace(\"\\\\\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url generation block\n",
    "url = \"https://earthscience.stackexchange.com/questions/tagged/\"\n",
    "urlJson = [\n",
    "    {\n",
    "        \"tag\": \"climate-change\",\n",
    "        \"tab\": [ \"newest\" ],\n",
    "        \"page\": [ \"9\" ],\n",
    "        \"pagesize\": \"50\"\n",
    "    },\n",
    "    {\n",
    "        \"tag\": \"climate\",\n",
    "        \"tab\": [ \"newest\" ],\n",
    "        \"page\": [ \"5\", \"2\" ],\n",
    "        \"pagesize\": \"50\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for tagIndex, tag in enumerate(urlJson):\n",
    "    tagName = urlJson[tagIndex][\"tag\"] + \"?\"\n",
    "    tagUrl = url + tagName\n",
    "    for tabIndex, tab in enumerate(urlJson[tagIndex][\"tab\"]):\n",
    "        tabUrl = tagUrl + \"tab=\" + tab \n",
    "        maxRange = int(urlJson[tagIndex][\"page\"][tabIndex]) + 1\n",
    "        pageSize = urlJson[tagIndex][\"pagesize\"]\n",
    "        for page in range(1,maxRange,1):\n",
    "            finalUrl = tabUrl + \"&page=\" + str(page) + \"&pagesize=\" + pageSize\n",
    "            print(finalUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver1 = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "    driver1.get(url)\n",
    "    linkLists = driver1.find_elements_by_class_name(\"summary h3 a\")\n",
    "    count = 1\n",
    "    questionJson = []\n",
    "    for link in linkLists: \n",
    "        print(link.get_attribute('href'))\n",
    "        driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "        driver.get(link.get_attribute('href'))\n",
    "        \n",
    "        mainJson = {}\n",
    "        # Question Header Div\n",
    "        questionHeader = driver.find_element_by_id(\"question-header\")\n",
    "        mainJson[\"question\"] = questionHeader.find_element_by_tag_name(\"h1\").text\n",
    "\n",
    "        # Question Divs\n",
    "        question = driver.find_element_by_class_name(\"question\")\n",
    "        questionId = int(question.get_attribute(\"data-questionid\"))\n",
    "        mainJson[\"author\"] = question.find_element_by_xpath(\"//div[@class='user-details']/span[@class='d-none']\").get_attribute(\"innerHTML\")\n",
    "        mainJson[\"date\"] = getBeautifyDate(question.find_element_by_xpath(\"//div[@class='user-action-time']/span[@class='relativetime']\").get_attribute(\"title\"))\n",
    "        mainJson[\"text\"] = getBeautifyText(question.find_element_by_class_name(\"post-text\").text)\n",
    "\n",
    "        # Question Comments Div\n",
    "        mainJson[\"comments\"] = []\n",
    "        comments = question.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % questionId)\n",
    "        commentDiv = question.find_element_by_id(\"comments-%d\" % questionId)\n",
    "        ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")    \n",
    "        liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "        for li in liCommentDiv:\n",
    "            commentJson = {}\n",
    "            commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "            commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "            commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "            mainJson[\"comments\"].append(commentJson)\n",
    "\n",
    "\n",
    "        # Answers Div\n",
    "        mainJson[\"answers\"] = []\n",
    "        answersDiv = driver.find_element_by_id(\"answers\")\n",
    "        answers = answersDiv.find_elements_by_class_name(\"answer\")\n",
    "        for answer in answers:\n",
    "            answerJson = {}\n",
    "            answerId = int(answer.get_attribute(\"data-answerid\"))\n",
    "            userInfos = answer.find_elements_by_class_name(\"user-info\")\n",
    "            for userInfo in userInfos:\n",
    "                userActionTime = userInfo.find_element_by_class_name(\"user-action-time\")\n",
    "                innerHTML = userActionTime.get_attribute(\"innerHTML\")\n",
    "                pattern = re.compile(r'answered', re.I)\n",
    "                if pattern.search(innerHTML) is not None:\n",
    "                    answerJson[\"author\"] = userInfo.find_element_by_class_name(\"d-none\").get_attribute(\"innerHTML\")\n",
    "                    answerJson[\"date\"] = getBeautifyDate(userInfo.find_element_by_class_name(\"relativetime\").get_attribute(\"title\"))\n",
    "            answerJson[\"text\"] = getBeautifyText(answer.find_element_by_class_name(\"post-text\").text)\n",
    "\n",
    "            # Anser Comments Div\n",
    "            answerJson[\"comments\"] = []\n",
    "            commentsJson = {}\n",
    "            comments = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % answerId)\n",
    "            commentDiv = answer.find_element_by_id(\"comments-%d\" % answerId)\n",
    "            ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")\n",
    "\n",
    "            # Check if some comments are not expanded \n",
    "            dataRemainingCommentsCount = int(ulCommentDiv.get_attribute(\"data-remaining-comments-count\"))\n",
    "            if(dataRemainingCommentsCount != 0):\n",
    "                commentsLink = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-link-%d']\" % answerId)\n",
    "                element = commentsLink.find_element_by_partial_link_text('show')\n",
    "                driver.execute_script(\"arguments[0].click();\", element)\n",
    "                sleep(1) # seconds\n",
    "                liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "                for li in liCommentDiv:\n",
    "                    commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                    commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                    commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                    answerJson[\"comments\"].append(commentJson)\n",
    "            else:\n",
    "                liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "                for li in liCommentDiv:\n",
    "                    commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                    commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                    commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                    answerJson[\"comments\"].append(commentJson)\n",
    "            mainJson[\"answers\"].append(answerJson)\n",
    "\n",
    "        # Create Json File \n",
    "        questionJson.append(mainJson)\n",
    "        driver.close()\n",
    "        count +=1\n",
    "        if(count == 5):\n",
    "            break\n",
    "\n",
    "    newJson = json.dumps(questionJson)\n",
    "    with open(\"myJson.json\", \"w\") as f:\n",
    "        f.write(newJson)\n",
    "    driver1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "mainJson = {}\n",
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Question Header Div\n",
    "    questionHeader = driver.find_element_by_id(\"question-header\")\n",
    "    mainJson[\"question\"] = questionHeader.find_element_by_tag_name(\"h1\").text\n",
    "    \n",
    "    # Question Divs\n",
    "    question = driver.find_element_by_class_name(\"question\")\n",
    "    questionId = int(question.get_attribute(\"data-questionid\"))\n",
    "    mainJson[\"author\"] = question.find_element_by_xpath(\"//div[@class='user-details']/span[@class='d-none']\").get_attribute(\"innerHTML\")\n",
    "    mainJson[\"date\"] = getBeautifyDate(question.find_element_by_xpath(\"//div[@class='user-action-time']/span[@class='relativetime']\").get_attribute(\"title\"))\n",
    "    mainJson[\"text\"] = getBeautifyText(question.find_element_by_class_name(\"post-text\").text)\n",
    "    \n",
    "    # Question Comments Div\n",
    "    mainJson[\"comments\"] = []\n",
    "    comments = question.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % questionId)\n",
    "    commentDiv = question.find_element_by_id(\"comments-%d\" % questionId)\n",
    "    ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")    \n",
    "    liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "    for li in liCommentDiv:\n",
    "        commentJson = {}\n",
    "        commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "        commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "        commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "        mainJson[\"comments\"].append(commentJson)\n",
    "    \n",
    "\n",
    "    # Answers Div\n",
    "    mainJson[\"answers\"] = []\n",
    "    answersDiv = driver.find_element_by_id(\"answers\")\n",
    "    answers = answersDiv.find_elements_by_class_name(\"answer\")\n",
    "    for answer in answers:\n",
    "        answerJson = {}\n",
    "        answerId = int(answer.get_attribute(\"data-answerid\"))\n",
    "        userInfos = answer.find_elements_by_class_name(\"user-info\")\n",
    "        for userInfo in userInfos:\n",
    "            userActionTime = userInfo.find_element_by_class_name(\"user-action-time\")\n",
    "            innerHTML = userActionTime.get_attribute(\"innerHTML\")\n",
    "            pattern = re.compile(r'answered', re.I)\n",
    "            if pattern.search(innerHTML) is not None:\n",
    "                answerJson[\"author\"] = userInfo.find_element_by_class_name(\"d-none\").get_attribute(\"innerHTML\")\n",
    "                answerJson[\"date\"] = getBeautifyDate(userInfo.find_element_by_class_name(\"relativetime\").get_attribute(\"title\"))\n",
    "        answerJson[\"text\"] = getBeautifyText(answer.find_element_by_class_name(\"post-text\").text)\n",
    "                \n",
    "        # Anser Comments Div\n",
    "        answerJson[\"comments\"] = []\n",
    "        commentsJson = {}\n",
    "        comments = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % answerId)\n",
    "        commentDiv = answer.find_element_by_id(\"comments-%d\" % answerId)\n",
    "        ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")\n",
    "        \n",
    "        # Check if some comments are not expanded \n",
    "        dataRemainingCommentsCount = int(ulCommentDiv.get_attribute(\"data-remaining-comments-count\"))\n",
    "        if(dataRemainingCommentsCount != 0):\n",
    "            commentsLink = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-link-%d']\" % answerId)\n",
    "            element = commentsLink.find_element_by_partial_link_text('show')\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            sleep(1) # seconds\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        else:\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        mainJson[\"answers\"].append(answerJson)\n",
    "\n",
    "# Create Json File \n",
    "newJson = json.dumps(mainJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(newJson)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    list = driver.find_elements_by_css_selector('h3 a')\n",
    "    for a in list\n",
    "        print(a)\n",
    "        print(a.get_attribute('href'))\n",
    "        break\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Create and Import Json \n",
    "import json\n",
    "myJson = {\n",
    "    \"question\": \"first question\",\n",
    "    \"author\": \n",
    "    {\n",
    "        \"auto\": \"auto1\",\n",
    "        \"name\": \"nazmul hossain\"\n",
    "    }\n",
    "}\n",
    "s = json.dumps(myJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Url traverse by page number \n",
    "pages = 10\n",
    "\n",
    "for page in range(1,pages):\n",
    "# for url in open(\"list_of_urls.txt\").readlines():\n",
    "#     driver.get(url)\n",
    "\n",
    "    url = \"http://quotes.toscrape.com/js/page/\" + str(page) + \"/\"\n",
    "    driver.get(url)\n",
    "    items = len(driver.find_elements_by_class_name(\"quote\"))\n",
    "    total = []\n",
    "    for item in range(items):\n",
    "        quotes = driver.find_elements_by_class_name(\"quote\")\n",
    "        for quote in quotes:\n",
    "            quote_text = quote.find_element_by_class_name('text').text\n",
    "            author = quote.find_element_by_class_name('author').text\n",
    "            new = ((quote_text,author))\n",
    "            total.append(new)\n",
    "    df = pd.DataFrame(total,columns=['quote','author'])\n",
    "    df.to_csv('quoted.csv')\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
