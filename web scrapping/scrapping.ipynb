{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from time import sleep \n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "# driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    linkLists = driver.find_elements_by_class_name(\"summary h3 a\")\n",
    "    for link in linkLists: \n",
    "        print(link.get_attribute('href'))\n",
    "        driver.get(link.get_attribute('href'))\n",
    "        break\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDateTime(dateTimeString):\n",
    "    return dateTimeString.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "mainJson = {}\n",
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Question Header Div\n",
    "    questionHeader = driver.find_element_by_id(\"question-header\")\n",
    "    mainJson[\"question\"] = questionHeader.find_element_by_tag_name(\"h1\").text\n",
    "    \n",
    "    # Question Divs\n",
    "    question = driver.find_element_by_class_name(\"question\")\n",
    "    questionId = int(question.get_attribute(\"data-questionid\"))\n",
    "    mainJson[\"author\"] = question.find_element_by_xpath(\"//div[@class='user-details']/span[@class='d-none']\").get_attribute(\"innerHTML\")\n",
    "    mainJson[\"date\"] = getDateTime(question.find_element_by_xpath(\"//div[@class='user-action-time']/span[@class='relativetime']\").get_attribute(\"title\"))\n",
    "    mainJson[\"text\"] = question.find_element_by_class_name(\"post-text\").text\n",
    "    \n",
    "    # Question Comments Div\n",
    "    mainJson[\"comments\"] = []\n",
    "    comments = question.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % questionId)\n",
    "    commentDiv = question.find_element_by_id(\"comments-%d\" % questionId)\n",
    "    ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")    \n",
    "    liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "    for li in liCommentDiv:\n",
    "        commentJson = {}\n",
    "        commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "        commentJson[\"date\"] = getDateTime(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "        commentJson[\"text\"] = li.find_element_by_class_name(\"comment-copy\").text\n",
    "        mainJson[\"comments\"].append(commentJson)\n",
    "    \n",
    "\n",
    "    # Answers Div\n",
    "    mainJson[\"answers\"] = []\n",
    "    answersDiv = driver.find_element_by_id(\"answers\")\n",
    "    answers = answersDiv.find_elements_by_class_name(\"answer\")\n",
    "    for answer in answers:\n",
    "        answerJson = {}\n",
    "        answerId = int(answer.get_attribute(\"data-answerid\"))\n",
    "        userInfos = answer.find_elements_by_class_name(\"user-info\")\n",
    "        for userInfo in userInfos:\n",
    "            userActionTime = userInfo.find_element_by_class_name(\"user-action-time\")\n",
    "            innerHTML = userActionTime.get_attribute(\"innerHTML\")\n",
    "            pattern = re.compile(r'answered', re.I)\n",
    "            if pattern.search(innerHTML) is not None:\n",
    "                answerJson[\"author\"] = userInfo.find_element_by_class_name(\"d-none\").get_attribute(\"innerHTML\")\n",
    "                answerJson[\"date\"] = getDateTime(userInfo.find_element_by_class_name(\"relativetime\").get_attribute(\"title\"))\n",
    "        answerJson[\"text\"] = answer.find_element_by_class_name(\"post-text\").text\n",
    "                \n",
    "        # Anser Comments Div\n",
    "        answerJson[\"comments\"] = []\n",
    "        commentsJson = {}\n",
    "        comments = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % answerId)\n",
    "        commentDiv = answer.find_element_by_id(\"comments-%d\" % answerId)\n",
    "        ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")\n",
    "        \n",
    "        # Check if some comments are not expanded \n",
    "        dataRemainingCommentsCount = int(ulCommentDiv.get_attribute(\"data-remaining-comments-count\"))\n",
    "        if(dataRemainingCommentsCount != 0):\n",
    "            commentsLink = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-link-%d']\" % answerId)\n",
    "            element = commentsLink.find_element_by_partial_link_text('show')\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            sleep(1) # seconds\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getDateTime(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = li.find_element_by_class_name(\"comment-copy\").text\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        else:\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getDateTime(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = li.find_element_by_class_name(\"comment-copy\").text\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        mainJson[\"answers\"].append(answerJson)\n",
    "s = json.dumps(mainJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(s)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    list = driver.find_elements_by_css_selector('h3 a')\n",
    "    for a in list\n",
    "        print(a)\n",
    "        print(a.get_attribute('href'))\n",
    "        break\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Create and Import Json \n",
    "import json\n",
    "myJson = {\n",
    "    \"question\": \"first question\",\n",
    "    \"author\": \n",
    "    {\n",
    "        \"auto\": \"auto1\",\n",
    "        \"name\": \"nazmul hossain\"\n",
    "    }\n",
    "}\n",
    "s = json.dumps(myJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Url traverse by page number \n",
    "pages = 10\n",
    "\n",
    "for page in range(1,pages):\n",
    "# for url in open(\"list_of_urls.txt\").readlines():\n",
    "#     driver.get(url)\n",
    "\n",
    "    url = \"http://quotes.toscrape.com/js/page/\" + str(page) + \"/\"\n",
    "    driver.get(url)\n",
    "    items = len(driver.find_elements_by_class_name(\"quote\"))\n",
    "    total = []\n",
    "    for item in range(items):\n",
    "        quotes = driver.find_elements_by_class_name(\"quote\")\n",
    "        for quote in quotes:\n",
    "            quote_text = quote.find_element_by_class_name('text').text\n",
    "            author = quote.find_element_by_class_name('author').text\n",
    "            new = ((quote_text,author))\n",
    "            total.append(new)\n",
    "    df = pd.DataFrame(total,columns=['quote','author'])\n",
    "    df.to_csv('quoted.csv')\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
