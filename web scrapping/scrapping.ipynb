{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from time import sleep \n",
    "from random import randint\n",
    "from selenium import webdriver\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyDate(dateTimeString):\n",
    "    return dateTimeString.split(\" \")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyText(text):\n",
    "#     return text.replace('\\n', '').replace(\"\\\\\", \"\").replace(\"\\u2666\",\"\").replace(\"\\u00b1\", \"\").replace(\"\\u2026\",\"\")\n",
    "     return unidecode(text.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Url generation block\n",
    "url = \"https://earthscience.stackexchange.com/questions/tagged/\"\n",
    "urlJson = [\n",
    "    {\n",
    "        \"tag\": \"climatology\",\n",
    "        \"tab\": [ \"newest\"],\n",
    "        \"page\": [ \"2\" ],\n",
    "        \"pagesize\": \"50\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Write url into text file\n",
    "for tagIndex, tag in enumerate(urlJson):\n",
    "    tagName = urlJson[tagIndex][\"tag\"] + \"?\" \n",
    "    tagUrl = url + tagName\n",
    "    for tabIndex, tab in enumerate(urlJson[tagIndex][\"tab\"]):\n",
    "        tabUrl = tagUrl + \"tab=\" + tab \n",
    "        maxRange = int(urlJson[tagIndex][\"page\"][tabIndex]) + 1\n",
    "        pageSize = urlJson[tagIndex][\"pagesize\"]\n",
    "        for page in range(1,maxRange,1):\n",
    "            finalUrl = tabUrl + \"&page=\" + str(page) + \"&pagesize=\" + pageSize + \"\\n\"\n",
    "            with open(\"list_of_urls.txt\", \"a\") as f:\n",
    "                f.write(finalUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileJson = []\n",
    "count = 0\n",
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    count += 1\n",
    "    print(url)\n",
    "    driver1 = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "    driver1.get(url)\n",
    "    linkLists = driver1.find_elements_by_class_name(\"summary h3 a\")\n",
    "    questionJson = []\n",
    "    for link in linkLists: \n",
    "        driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "        driver.get(link.get_attribute('href'))\n",
    "        \n",
    "        mainJson = {}\n",
    "        # Question Header Div\n",
    "        questionHeader = driver.find_element_by_id(\"question-header\")\n",
    "        mainJson[\"question\"] = questionHeader.find_element_by_tag_name(\"h1\").text\n",
    "\n",
    "        # Question Divs\n",
    "        question = driver.find_element_by_class_name(\"question\")\n",
    "        questionId = int(question.get_attribute(\"data-questionid\"))\n",
    "        mainJson[\"author\"] = getBeautifyText(question.find_element_by_xpath(\"//div[@class='user-details']/span[@class='d-none']\").get_attribute(\"innerHTML\"))\n",
    "        mainJson[\"date\"] = getBeautifyDate(question.find_element_by_xpath(\"//div[@class='user-action-time']/span[@class='relativetime']\").get_attribute(\"title\"))\n",
    "        mainJson[\"text\"] = getBeautifyText(question.find_element_by_class_name(\"post-text\").text)\n",
    "\n",
    "        # Question Comments Div\n",
    "        mainJson[\"answers\"] = []\n",
    "        comments = question.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % questionId)\n",
    "        commentDiv = question.find_element_by_id(\"comments-%d\" % questionId)\n",
    "        ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")    \n",
    "        liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "        for li in liCommentDiv:\n",
    "            commentJson = {}\n",
    "            commentJson[\"author\"] = getBeautifyText(li.find_element_by_class_name(\"comment-user\").text)\n",
    "            commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "            commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "            commentJson[\"answers\"] = []\n",
    "            mainJson[\"answers\"].append(commentJson)\n",
    "\n",
    "\n",
    "        # Answers Div\n",
    "        mainJson[\"answers\"] = []\n",
    "        answersDiv = driver.find_element_by_id(\"answers\")\n",
    "        answers = answersDiv.find_elements_by_class_name(\"answer\")\n",
    "        for answer in answers:\n",
    "            answerJson = {}\n",
    "            answerId = int(answer.get_attribute(\"data-answerid\"))\n",
    "            userInfos = answer.find_elements_by_class_name(\"user-info\")\n",
    "            for userInfo in userInfos:\n",
    "                userActionTime = userInfo.find_element_by_class_name(\"user-action-time\")\n",
    "                innerHTML = userActionTime.get_attribute(\"innerHTML\")\n",
    "                pattern = re.compile(r'answered', re.I)\n",
    "                if pattern.search(innerHTML) is not None:\n",
    "                    answerJson[\"author\"] = getBeautifyText(userInfo.find_element_by_class_name(\"d-none\").get_attribute(\"innerHTML\"))\n",
    "                    answerJson[\"date\"] = getBeautifyDate(userInfo.find_element_by_class_name(\"relativetime\").get_attribute(\"title\"))\n",
    "            answerJson[\"text\"] = getBeautifyText(answer.find_element_by_class_name(\"post-text\").text)\n",
    "\n",
    "            # Anser Comments Div\n",
    "            answerJson[\"answers\"] = []\n",
    "            commentsJson = {}\n",
    "            comments = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % answerId)\n",
    "            commentDiv = answer.find_element_by_id(\"comments-%d\" % answerId)\n",
    "            ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")\n",
    "\n",
    "            # Check if some comments are not expanded \n",
    "            dataRemainingCommentsCount = int(ulCommentDiv.get_attribute(\"data-remaining-comments-count\"))\n",
    "            if(dataRemainingCommentsCount != 0):\n",
    "                commentsLink = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-link-%d']\" % answerId)\n",
    "                element = commentsLink.find_element_by_partial_link_text('show')\n",
    "                driver.execute_script(\"arguments[0].click();\", element)\n",
    "                sleep(5) # seconds\n",
    "                liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "                for li in liCommentDiv:\n",
    "                    commentJson = {}\n",
    "                    commentJson[\"author\"] = getBeautifyText(li.find_element_by_class_name(\"comment-user\").text)\n",
    "                    commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                    commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                    commentJson[\"answers\"] = []\n",
    "                    answerJson[\"answers\"].append(commentJson)\n",
    "            else:\n",
    "                liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "                for li in liCommentDiv:\n",
    "                    commentJson = {}\n",
    "                    commentJson[\"author\"] = getBeautifyText(li.find_element_by_class_name(\"comment-user\").text)\n",
    "                    commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                    commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                    commentJson[\"answers\"] = []\n",
    "                    answerJson[\"answers\"].append(commentJson)\n",
    "            mainJson[\"answers\"].append(answerJson)\n",
    "\n",
    "        # Create Json File \n",
    "        questionJson.append(mainJson)\n",
    "        driver.close()\n",
    "        fileJson += questionJson\n",
    "    driver1.close()\n",
    "    \n",
    "    newJson = json.dumps(fileJson)\n",
    "    with open(\"climatology-\" + str(count) + \".json\", \"w\") as f:\n",
    "        f.write(newJson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ( You don't need)\n",
    "driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe') \n",
    "mainJson = {}\n",
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Question Header Div\n",
    "    questionHeader = driver.find_element_by_id(\"question-header\")\n",
    "    mainJson[\"question\"] = questionHeader.find_element_by_tag_name(\"h1\").text\n",
    "    \n",
    "    # Question Divs\n",
    "    question = driver.find_element_by_class_name(\"question\")\n",
    "    questionId = int(question.get_attribute(\"data-questionid\"))\n",
    "    mainJson[\"author\"] = question.find_element_by_xpath(\"//div[@class='user-details']/span[@class='d-none']\").get_attribute(\"innerHTML\")\n",
    "    mainJson[\"date\"] = getBeautifyDate(question.find_element_by_xpath(\"//div[@class='user-action-time']/span[@class='relativetime']\").get_attribute(\"title\"))\n",
    "    mainJson[\"text\"] = getBeautifyText(question.find_element_by_class_name(\"post-text\").text)\n",
    "    \n",
    "    # Question Comments Div\n",
    "    mainJson[\"comments\"] = []\n",
    "    comments = question.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % questionId)\n",
    "    commentDiv = question.find_element_by_id(\"comments-%d\" % questionId)\n",
    "    ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")    \n",
    "    liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "    for li in liCommentDiv:\n",
    "        commentJson = {}\n",
    "        commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "        commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "        commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "        mainJson[\"comments\"].append(commentJson)\n",
    "    \n",
    "\n",
    "    # Answers Div\n",
    "    mainJson[\"answers\"] = []\n",
    "    answersDiv = driver.find_element_by_id(\"answers\")\n",
    "    answers = answersDiv.find_elements_by_class_name(\"answer\")\n",
    "    for answer in answers:\n",
    "        answerJson = {}\n",
    "        answerId = int(answer.get_attribute(\"data-answerid\"))\n",
    "        userInfos = answer.find_elements_by_class_name(\"user-info\")\n",
    "        for userInfo in userInfos:\n",
    "            userActionTime = userInfo.find_element_by_class_name(\"user-action-time\")\n",
    "            innerHTML = userActionTime.get_attribute(\"innerHTML\")\n",
    "            pattern = re.compile(r'answered', re.I)\n",
    "            if pattern.search(innerHTML) is not None:\n",
    "                answerJson[\"author\"] = userInfo.find_element_by_class_name(\"d-none\").get_attribute(\"innerHTML\")\n",
    "                answerJson[\"date\"] = getBeautifyDate(userInfo.find_element_by_class_name(\"relativetime\").get_attribute(\"title\"))\n",
    "        answerJson[\"text\"] = getBeautifyText(answer.find_element_by_class_name(\"post-text\").text)\n",
    "                \n",
    "        # Anser Comments Div\n",
    "        answerJson[\"comments\"] = []\n",
    "        commentsJson = {}\n",
    "        comments = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-%d']\" % answerId)\n",
    "        commentDiv = answer.find_element_by_id(\"comments-%d\" % answerId)\n",
    "        ulCommentDiv = commentDiv.find_element_by_class_name(\"comments-list\")\n",
    "        \n",
    "        # Check if some comments are not expanded \n",
    "        dataRemainingCommentsCount = int(ulCommentDiv.get_attribute(\"data-remaining-comments-count\"))\n",
    "        if(dataRemainingCommentsCount != 0):\n",
    "            commentsLink = answer.find_element_by_xpath(\"//div[@class='post-layout--right']/div[@id='comments-link-%d']\" % answerId)\n",
    "            element = commentsLink.find_element_by_partial_link_text('show')\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            sleep(1) # seconds\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        else:\n",
    "            liCommentDiv = ulCommentDiv.find_elements_by_class_name(\"comment\")\n",
    "            for li in liCommentDiv:\n",
    "                commentJson[\"author\"] = li.find_element_by_class_name(\"comment-user\").text\n",
    "                commentJson[\"date\"] = getBeautifyDate(li.find_element_by_class_name(\"relativetime-clean\").get_attribute(\"title\"))\n",
    "                commentJson[\"text\"] = getBeautifyText(li.find_element_by_class_name(\"comment-copy\").text)\n",
    "                answerJson[\"comments\"].append(commentJson)\n",
    "        mainJson[\"answers\"].append(answerJson)\n",
    "\n",
    "# Create Json File \n",
    "newJson = json.dumps(mainJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(newJson)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ( You don't need)\n",
    "for url in open(\"list_of_urls.txt\").readlines():\n",
    "    driver.get(url)\n",
    "    list = driver.find_elements_by_css_selector('h3 a')\n",
    "    for a in list\n",
    "        print(a)\n",
    "        print(a.get_attribute('href'))\n",
    "        break\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ( You don't need)\n",
    "# Example Create and Import Json \n",
    "import json\n",
    "myJson = {\n",
    "    \"question\": \"first question\",\n",
    "    \"author\": \n",
    "    {\n",
    "        \"auto\": \"auto1\",\n",
    "        \"name\": \"nazmul hossain\"\n",
    "    }\n",
    "}\n",
    "s = json.dumps(myJson)\n",
    "with open(\"myJson.json\", \"w\") as f:\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ( You don't need)\n",
    "# Example Url traverse by page number \n",
    "pages = 10\n",
    "\n",
    "for page in range(1,pages):\n",
    "# for url in open(\"list_of_urls.txt\").readlines():\n",
    "#     driver.get(url)\n",
    "\n",
    "    url = \"http://quotes.toscrape.com/js/page/\" + str(page) + \"/\"\n",
    "    driver.get(url)\n",
    "    items = len(driver.find_elements_by_class_name(\"quote\"))\n",
    "    total = []\n",
    "    for item in range(items):\n",
    "        quotes = driver.find_elements_by_class_name(\"quote\")\n",
    "        for quote in quotes:\n",
    "            quote_text = quote.find_element_by_class_name('text').text\n",
    "            author = quote.find_element_by_class_name('author').text\n",
    "            new = ((quote_text,author))\n",
    "            total.append(new)\n",
    "    df = pd.DataFrame(total,columns=['quote','author'])\n",
    "    df.to_csv('quoted.csv')\n",
    "    sleep_for = randint(300,2500) / 1000.0\n",
    "    sleep( sleep_for )\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example ( You don't need)\n",
    "# Merge Json\n",
    "import json\n",
    "\n",
    "list_1 = [\n",
    "    {'title': 'THE COMPLETE PYTHON WEB COURSE', 'downloads': '4', 'views': '88'}, \n",
    "    {'title': 'THE COMPLETE JAVA WEB COURSE', 'downloads': '16', 'views': '156'}]\n",
    "\n",
    "list_2 = [\n",
    "    {'title': 'THE COMPLETE GUITAR COURSE', 'downloads': '18', 'views': '125'}, \n",
    "    {'title': 'THE COMPLETE KEYBOARD COURSE', 'downloads': '63', 'views': '98'}]\n",
    "res_dict = {}\n",
    "res_dict =  list_1 + list_2 \n",
    "\n",
    "to_json = json.dumps(res_dict)\n",
    "print(to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Tab and Close the Tab \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe')\n",
    "driver.get(\"http://www.google.com/\")\n",
    "\n",
    "#open tab\n",
    "# driver.find_element_by_tag_name('body').send_keys(Keys.COMMAND + Keys.TAB) \n",
    "# You can use (Keys.CONTROL + 't') on other OSs\n",
    "driver.execute_script(\"window.open('http://stackoverflow.com/', 'new_window')\")\n",
    "\n",
    "# driver.switch_to.window(driver.window_handles[0])\n",
    "# Load a page \n",
    "# driver.get('http://stackoverflow.com/')\n",
    "# Make the tests...\n",
    "\n",
    "# close the tab\n",
    "# (Keys.CONTROL + 'w') on other OSs.\n",
    "driver.find_element_by_tag_name('body').send_keys(Keys.COMMAND + 'w') \n",
    "\n",
    "\n",
    "# driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('H:\\Digital_Media\\climate_change\\climate-chatbot\\chromedriver_win32\\chromedriver.exe')\n",
    "\n",
    "# Open a new window\n",
    "# This does not change focus to the new window for the driver.\n",
    "driver.execute_script(\"window.open('http://google.com');\")\n",
    "# driver.get(\"http://google.com\")\n",
    "\n",
    "# Switch to the new windoww\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "driver.get(\"http://stackoverflow.com\")\n",
    "\n",
    "# close the active tab\n",
    "driver.close()\n",
    "\n",
    "# Switch back to the first tab\n",
    "driver.switch_to.window(driver.window_handles[0])\n",
    "driver.get(\"http://google.com\")\n",
    "\n",
    "# Close the only tab, will also close the browser.\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
