{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json\n",
    "from unidecode import unidecode\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "from nltk.stem import *\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBeautifyText(text):\n",
    "     return unidecode(text.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only question\n",
    "# Get all json file from data directory\n",
    "path_to_json = 'data/'\n",
    "columns = ['question']\n",
    "questionAndAnswerDf = pd.DataFrame(columns=columns)\n",
    "indexCount = 0\n",
    "for pos_json in os.listdir(path_to_json):\n",
    "    if pos_json.endswith('.json'):\n",
    "        with open(path_to_json + pos_json, encoding=\"utf8\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            for index, questionObject in enumerate(data):\n",
    "                questionAndAnswerDf.loc[indexCount] = [getBeautifyText(questionObject[\"question\"])]\n",
    "                indexCount += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>How do you compare Methane Ppm and carbon(iv) ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Equatorial Bulge and its implications on the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Where oil is used for [closed]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Rain Water vs Sprinkler Irrigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Climate Change in the North</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question\n",
       "0  How do you compare Methane Ppm and carbon(iv) ...\n",
       "1  Equatorial Bulge and its implications on the c...\n",
       "2                     Where oil is used for [closed]\n",
       "3                 Rain Water vs Sprinkler Irrigation\n",
       "4                        Climate Change in the North"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionAndAnswerDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3233\n"
     ]
    }
   ],
   "source": [
    "print(len(questionAndAnswerDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize text \n",
    "def lemmatize_stemming(text):\n",
    "    stemmer=PorterStemmer()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text processing \n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question: \n",
      "['How', 'do', 'you', 'compare', 'Methane', 'Ppm', 'and', 'carbon(iv)', 'oxide', '[closed]']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['compar', 'methan', 'carbon', 'oxid', 'close']\n"
     ]
    }
   ],
   "source": [
    "# apply texgt pre processing (1st question)\n",
    "questionSample = questionAndAnswerDf.iloc[0]['question']\n",
    "\n",
    "print('Original question: ')\n",
    "words = []\n",
    "for word in questionSample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(questionSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [compar, methan, carbon, oxid, close]\n",
       "1         [equatori, bulg, implic, climat]\n",
       "2                                  [close]\n",
       "3          [rain, water, sprinkler, irrig]\n",
       "4                   [climat, chang, north]\n",
       "Name: question, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create one process dataset \n",
    "processDf = questionAndAnswerDf['question'].map(preprocess)\n",
    "processDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 carbon\n",
      "1 close\n",
      "2 compar\n",
      "3 methan\n",
      "4 oxid\n",
      "5 bulg\n",
      "6 climat\n",
      "7 equatori\n",
      "8 implic\n",
      "9 irrig\n",
      "10 rain\n"
     ]
    }
   ],
   "source": [
    "# apply beg of words\n",
    "dictionary = gensim.corpora.Dictionary(processDf)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out tokens that appear in \n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words and how many times those words appear\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processDf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(73, 1), (82, 1), (89, 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 73 (\"area\") appears 1 time.\n",
      "Word 82 (\"hotter\") appears 1 time.\n",
      "Word 89 (\"winter\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "# Preview Bag Of Words for our sample preprocessed document\n",
    "bow_doc_100 = bow_corpus[100]\n",
    "for i in range(len(bow_doc_100)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_100[i][0], \n",
    "                                               dictionary[bow_doc_100[i][0]], \n",
    "bow_doc_100[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4923813985714881), (1, 0.5224031771053126), (2, 0.6961720181758678)]\n"
     ]
    }
   ],
   "source": [
    "# Create tf-idf model object using models\n",
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running LDA using Bag of Words\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.100*\"climat\" + 0.083*\"chang\" + 0.079*\"ocean\" + 0.060*\"heat\" + 0.035*\"go\" + 0.034*\"planet\" + 0.029*\"pollut\" + 0.023*\"life\" + 0.023*\"stop\" + 0.023*\"fight\"\n",
      "Topic: 1 \n",
      "Words: 0.073*\"earth\" + 0.051*\"climat\" + 0.038*\"chang\" + 0.037*\"emiss\" + 0.037*\"problem\" + 0.035*\"human\" + 0.031*\"ipcc\" + 0.029*\"arctic\" + 0.027*\"experi\" + 0.026*\"carbon\"\n",
      "Topic: 2 \n",
      "Words: 0.218*\"climat\" + 0.135*\"chang\" + 0.039*\"model\" + 0.036*\"data\" + 0.035*\"temperatur\" + 0.031*\"increas\" + 0.028*\"rise\" + 0.027*\"level\" + 0.023*\"atmospher\" + 0.022*\"global\"\n",
      "Topic: 3 \n",
      "Words: 0.119*\"climat\" + 0.094*\"temperatur\" + 0.048*\"year\" + 0.043*\"averag\" + 0.039*\"earth\" + 0.034*\"chang\" + 0.023*\"global\" + 0.022*\"feedback\" + 0.018*\"model\" + 0.017*\"question\"\n",
      "Topic: 4 \n",
      "Words: 0.172*\"climat\" + 0.125*\"chang\" + 0.067*\"world\" + 0.032*\"scientist\" + 0.030*\"water\" + 0.026*\"differ\" + 0.024*\"impact\" + 0.021*\"school\" + 0.019*\"look\" + 0.019*\"strike\"\n",
      "Topic: 5 \n",
      "Words: 0.109*\"greenhous\" + 0.102*\"effect\" + 0.044*\"close\" + 0.040*\"time\" + 0.039*\"carbon\" + 0.029*\"fuel\" + 0.028*\"plant\" + 0.027*\"ga\" + 0.027*\"atmospher\" + 0.026*\"fossil\"\n",
      "Topic: 6 \n",
      "Words: 0.242*\"warm\" + 0.226*\"global\" + 0.027*\"scienc\" + 0.018*\"cool\" + 0.017*\"carbon\" + 0.016*\"level\" + 0.016*\"happen\" + 0.015*\"atmospher\" + 0.014*\"earth\" + 0.014*\"water\"\n",
      "Topic: 7 \n",
      "Words: 0.225*\"climat\" + 0.180*\"chang\" + 0.056*\"earth\" + 0.048*\"affect\" + 0.035*\"natur\" + 0.030*\"energi\" + 0.018*\"theori\" + 0.018*\"atmospher\" + 0.017*\"peopl\" + 0.016*\"trump\"\n",
      "Topic: 8 \n",
      "Words: 0.070*\"climat\" + 0.064*\"caus\" + 0.063*\"temperatur\" + 0.060*\"global\" + 0.060*\"chang\" + 0.049*\"like\" + 0.025*\"weather\" + 0.023*\"winter\" + 0.021*\"countri\" + 0.021*\"atmospher\"\n",
      "Topic: 9 \n",
      "Words: 0.101*\"climat\" + 0.090*\"chang\" + 0.038*\"year\" + 0.034*\"melt\" + 0.028*\"measur\" + 0.027*\"build\" + 0.026*\"power\" + 0.026*\"global\" + 0.024*\"make\" + 0.023*\"citi\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.097*\"global\" + 0.089*\"warm\" + 0.053*\"rise\" + 0.047*\"caus\" + 0.045*\"climat\" + 0.043*\"level\" + 0.039*\"scientist\" + 0.034*\"chang\" + 0.032*\"trump\" + 0.032*\"human\"\n",
      "Topic: 1 Word: 0.131*\"climat\" + 0.061*\"earth\" + 0.044*\"greenhous\" + 0.039*\"affect\" + 0.037*\"scienc\" + 0.034*\"atmospher\" + 0.028*\"chang\" + 0.026*\"cloud\" + 0.025*\"believ\" + 0.024*\"heat\"\n",
      "Topic: 2 Word: 0.121*\"ocean\" + 0.085*\"increas\" + 0.046*\"happen\" + 0.038*\"close\" + 0.032*\"earth\" + 0.031*\"time\" + 0.031*\"green\" + 0.030*\"stop\" + 0.029*\"temperatur\" + 0.027*\"gener\"\n",
      "Topic: 3 Word: 0.099*\"temperatur\" + 0.076*\"warm\" + 0.067*\"global\" + 0.038*\"record\" + 0.029*\"data\" + 0.029*\"problem\" + 0.028*\"land\" + 0.026*\"emiss\" + 0.025*\"peopl\" + 0.025*\"earth\"\n",
      "Topic: 4 Word: 0.060*\"heat\" + 0.047*\"model\" + 0.040*\"question\" + 0.034*\"melt\" + 0.032*\"climat\" + 0.028*\"ipcc\" + 0.026*\"life\" + 0.026*\"china\" + 0.025*\"chang\" + 0.024*\"current\"\n",
      "Topic: 5 Word: 0.196*\"chang\" + 0.158*\"climat\" + 0.036*\"energi\" + 0.028*\"denier\" + 0.027*\"come\" + 0.025*\"need\" + 0.025*\"help\" + 0.020*\"event\" + 0.019*\"global\" + 0.018*\"north\"\n",
      "Topic: 6 Word: 0.042*\"water\" + 0.041*\"build\" + 0.038*\"countri\" + 0.036*\"chang\" + 0.033*\"climat\" + 0.032*\"theori\" + 0.030*\"fight\" + 0.028*\"like\" + 0.027*\"close\" + 0.026*\"fuel\"\n",
      "Topic: 7 Word: 0.120*\"climat\" + 0.108*\"chang\" + 0.045*\"weather\" + 0.045*\"impact\" + 0.039*\"model\" + 0.032*\"increas\" + 0.031*\"radiat\" + 0.028*\"flood\" + 0.026*\"caus\" + 0.023*\"natur\"\n",
      "Topic: 8 Word: 0.070*\"effect\" + 0.063*\"world\" + 0.060*\"climat\" + 0.059*\"chang\" + 0.056*\"carbon\" + 0.048*\"warm\" + 0.044*\"global\" + 0.028*\"cool\" + 0.027*\"dioxid\" + 0.025*\"scientist\"\n",
      "Topic: 9 Word: 0.069*\"differ\" + 0.060*\"year\" + 0.054*\"planet\" + 0.042*\"protest\" + 0.040*\"futur\" + 0.037*\"cycl\" + 0.034*\"better\" + 0.029*\"save\" + 0.027*\"citi\" + 0.026*\"arctic\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using TF-IDF\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vietnam',\n",
       " 'highland',\n",
       " 'colder',\n",
       " 'winter',\n",
       " 'hotter',\n",
       " 'summer',\n",
       " 'lower',\n",
       " 'lie',\n",
       " 'area']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance evaluation by classifying sample document using LDA Bag of Words model\n",
    "processDf[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.7749512195587158\t \n",
      "Topic: 0.119*\"climat\" + 0.094*\"temperatur\" + 0.048*\"year\" + 0.043*\"averag\" + 0.039*\"earth\" + 0.034*\"chang\" + 0.023*\"global\" + 0.022*\"feedback\" + 0.018*\"model\" + 0.017*\"question\"\n",
      "\n",
      "Score: 0.02501291036605835\t \n",
      "Topic: 0.070*\"climat\" + 0.064*\"caus\" + 0.063*\"temperatur\" + 0.060*\"global\" + 0.060*\"chang\" + 0.049*\"like\" + 0.025*\"weather\" + 0.023*\"winter\" + 0.021*\"countri\" + 0.021*\"atmospher\"\n",
      "\n",
      "Score: 0.025010153651237488\t \n",
      "Topic: 0.242*\"warm\" + 0.226*\"global\" + 0.027*\"scienc\" + 0.018*\"cool\" + 0.017*\"carbon\" + 0.016*\"level\" + 0.016*\"happen\" + 0.015*\"atmospher\" + 0.014*\"earth\" + 0.014*\"water\"\n",
      "\n",
      "Score: 0.025008363649249077\t \n",
      "Topic: 0.225*\"climat\" + 0.180*\"chang\" + 0.056*\"earth\" + 0.048*\"affect\" + 0.035*\"natur\" + 0.030*\"energi\" + 0.018*\"theori\" + 0.018*\"atmospher\" + 0.017*\"peopl\" + 0.016*\"trump\"\n",
      "\n",
      "Score: 0.025007443502545357\t \n",
      "Topic: 0.109*\"greenhous\" + 0.102*\"effect\" + 0.044*\"close\" + 0.040*\"time\" + 0.039*\"carbon\" + 0.029*\"fuel\" + 0.028*\"plant\" + 0.027*\"ga\" + 0.027*\"atmospher\" + 0.026*\"fossil\"\n",
      "\n",
      "Score: 0.02500319853425026\t \n",
      "Topic: 0.172*\"climat\" + 0.125*\"chang\" + 0.067*\"world\" + 0.032*\"scientist\" + 0.030*\"water\" + 0.026*\"differ\" + 0.024*\"impact\" + 0.021*\"school\" + 0.019*\"look\" + 0.019*\"strike\"\n",
      "\n",
      "Score: 0.025002852082252502\t \n",
      "Topic: 0.100*\"climat\" + 0.083*\"chang\" + 0.079*\"ocean\" + 0.060*\"heat\" + 0.035*\"go\" + 0.034*\"planet\" + 0.029*\"pollut\" + 0.023*\"life\" + 0.023*\"stop\" + 0.023*\"fight\"\n",
      "\n",
      "Score: 0.02500169537961483\t \n",
      "Topic: 0.101*\"climat\" + 0.090*\"chang\" + 0.038*\"year\" + 0.034*\"melt\" + 0.028*\"measur\" + 0.027*\"build\" + 0.026*\"power\" + 0.026*\"global\" + 0.024*\"make\" + 0.023*\"citi\"\n",
      "\n",
      "Score: 0.025001447647809982\t \n",
      "Topic: 0.073*\"earth\" + 0.051*\"climat\" + 0.038*\"chang\" + 0.037*\"emiss\" + 0.037*\"problem\" + 0.035*\"human\" + 0.031*\"ipcc\" + 0.029*\"arctic\" + 0.027*\"experi\" + 0.026*\"carbon\"\n",
      "\n",
      "Score: 0.025000756606459618\t \n",
      "Topic: 0.218*\"climat\" + 0.135*\"chang\" + 0.039*\"model\" + 0.036*\"data\" + 0.035*\"temperatur\" + 0.031*\"increas\" + 0.028*\"rise\" + 0.027*\"level\" + 0.023*\"atmospher\" + 0.022*\"global\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[100]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.5552629232406616\t \n",
      "Topic: 0.131*\"climat\" + 0.061*\"earth\" + 0.044*\"greenhous\" + 0.039*\"affect\" + 0.037*\"scienc\" + 0.034*\"atmospher\" + 0.028*\"chang\" + 0.026*\"cloud\" + 0.025*\"believ\" + 0.024*\"heat\"\n",
      "\n",
      "Score: 0.2446936070919037\t \n",
      "Topic: 0.120*\"climat\" + 0.108*\"chang\" + 0.045*\"weather\" + 0.045*\"impact\" + 0.039*\"model\" + 0.032*\"increas\" + 0.031*\"radiat\" + 0.028*\"flood\" + 0.026*\"caus\" + 0.023*\"natur\"\n",
      "\n",
      "Score: 0.02502145804464817\t \n",
      "Topic: 0.099*\"temperatur\" + 0.076*\"warm\" + 0.067*\"global\" + 0.038*\"record\" + 0.029*\"data\" + 0.029*\"problem\" + 0.028*\"land\" + 0.026*\"emiss\" + 0.025*\"peopl\" + 0.025*\"earth\"\n",
      "\n",
      "Score: 0.025007816031575203\t \n",
      "Topic: 0.069*\"differ\" + 0.060*\"year\" + 0.054*\"planet\" + 0.042*\"protest\" + 0.040*\"futur\" + 0.037*\"cycl\" + 0.034*\"better\" + 0.029*\"save\" + 0.027*\"citi\" + 0.026*\"arctic\"\n",
      "\n",
      "Score: 0.025004912167787552\t \n",
      "Topic: 0.097*\"global\" + 0.089*\"warm\" + 0.053*\"rise\" + 0.047*\"caus\" + 0.045*\"climat\" + 0.043*\"level\" + 0.039*\"scientist\" + 0.034*\"chang\" + 0.032*\"trump\" + 0.032*\"human\"\n",
      "\n",
      "Score: 0.025003699585795403\t \n",
      "Topic: 0.196*\"chang\" + 0.158*\"climat\" + 0.036*\"energi\" + 0.028*\"denier\" + 0.027*\"come\" + 0.025*\"need\" + 0.025*\"help\" + 0.020*\"event\" + 0.019*\"global\" + 0.018*\"north\"\n",
      "\n",
      "Score: 0.025002185255289078\t \n",
      "Topic: 0.042*\"water\" + 0.041*\"build\" + 0.038*\"countri\" + 0.036*\"chang\" + 0.033*\"climat\" + 0.032*\"theori\" + 0.030*\"fight\" + 0.028*\"like\" + 0.027*\"close\" + 0.026*\"fuel\"\n",
      "\n",
      "Score: 0.025001514703035355\t \n",
      "Topic: 0.121*\"ocean\" + 0.085*\"increas\" + 0.046*\"happen\" + 0.038*\"close\" + 0.032*\"earth\" + 0.031*\"time\" + 0.031*\"green\" + 0.030*\"stop\" + 0.029*\"temperatur\" + 0.027*\"gener\"\n",
      "\n",
      "Score: 0.025001076981425285\t \n",
      "Topic: 0.060*\"heat\" + 0.047*\"model\" + 0.040*\"question\" + 0.034*\"melt\" + 0.032*\"climat\" + 0.028*\"ipcc\" + 0.026*\"life\" + 0.026*\"china\" + 0.025*\"chang\" + 0.024*\"current\"\n",
      "\n",
      "Score: 0.025000765919685364\t \n",
      "Topic: 0.070*\"effect\" + 0.063*\"world\" + 0.060*\"climat\" + 0.059*\"chang\" + 0.056*\"carbon\" + 0.048*\"warm\" + 0.044*\"global\" + 0.028*\"cool\" + 0.027*\"dioxid\" + 0.025*\"scientist\"\n"
     ]
    }
   ],
   "source": [
    "# Performance evaluation by classifying sample document using LDA TF-IDF model.\n",
    "for index, score in sorted(lda_model_tfidf[bow_corpus[100]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.48230278491973877\t Topic: 0.225*\"climat\" + 0.180*\"chang\" + 0.056*\"earth\" + 0.048*\"affect\" + 0.035*\"natur\"\n",
      "Score: 0.31766024231910706\t Topic: 0.119*\"climat\" + 0.094*\"temperatur\" + 0.048*\"year\" + 0.043*\"averag\" + 0.039*\"earth\"\n",
      "Score: 0.025010138750076294\t Topic: 0.101*\"climat\" + 0.090*\"chang\" + 0.038*\"year\" + 0.034*\"melt\" + 0.028*\"measur\"\n",
      "Score: 0.02500765025615692\t Topic: 0.218*\"climat\" + 0.135*\"chang\" + 0.039*\"model\" + 0.036*\"data\" + 0.035*\"temperatur\"\n",
      "Score: 0.02500654011964798\t Topic: 0.100*\"climat\" + 0.083*\"chang\" + 0.079*\"ocean\" + 0.060*\"heat\" + 0.035*\"go\"\n",
      "Score: 0.025006357580423355\t Topic: 0.172*\"climat\" + 0.125*\"chang\" + 0.067*\"world\" + 0.032*\"scientist\" + 0.030*\"water\"\n",
      "Score: 0.02500297501683235\t Topic: 0.070*\"climat\" + 0.064*\"caus\" + 0.063*\"temperatur\" + 0.060*\"global\" + 0.060*\"chang\"\n",
      "Score: 0.025001974776387215\t Topic: 0.073*\"earth\" + 0.051*\"climat\" + 0.038*\"chang\" + 0.037*\"emiss\" + 0.037*\"problem\"\n",
      "Score: 0.025000790134072304\t Topic: 0.242*\"warm\" + 0.226*\"global\" + 0.027*\"scienc\" + 0.018*\"cool\" + 0.017*\"carbon\"\n",
      "Score: 0.025000527501106262\t Topic: 0.109*\"greenhous\" + 0.102*\"effect\" + 0.044*\"close\" + 0.040*\"time\" + 0.039*\"carbon\"\n"
     ]
    }
   ],
   "source": [
    "# Testing model on unseen document\n",
    "unseen_document = 'How a climate will be changed next few years'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
